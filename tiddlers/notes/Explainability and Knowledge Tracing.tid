about: 
color: #5778d7
created: 20180725153952278
creator: Charles Delbé
description: 
icon: $:/plugins/.CD/KnowEdge/images/note
list: [[Artificial Intelligence]] [[Knowledge Tracing]] Explainability
modified: 20181216084040505
modifier: Charles Delbé
mt-source.parents.list: 
mt-source.tiddler: Explainability
mt-topics.list: [[Artificial Intelligence]] [[Knowledge Tracing]] Explainability
tags: $:/type/note
title: Explainability and Knowledge Tracing
tmap.fa-icon: &#xf044;
tmap.id: 61c009a5-354e-468e-a2e5-0a660998839c
type: text/vnd.tiddlywiki

!!Interprétabilité des modèles de l'apprenant
Des modèles hautement ''structurés'' dont les paramètres ont une ''interprétation psychologique directe'' (tels que les modèles [[IRT|?]] et [[BKT|?]] à la base de la solution que nous proposons) fournissent généralement plus d'informations sur la cognition que les modèles profonds (i.e., [[Deep Knowledge Tracing]]; [[Corbett & Anderson (1995)|]]). Par ailleurs, l’évaluation de la compétence des apprenants, ou suivi des connaissances ([[Knowledge Tracing]]), ne semble pas être un domaine bénéficiant de la profondeur de traitement spécifiques aux modèles ''d'apprentissage profonds''; Les modèles "''peu profonds''" fonctionnent aussi bien et offrent une plus grande capacité d’interprétation et d’explication ([[Wilson et al. (2016)|]]).
